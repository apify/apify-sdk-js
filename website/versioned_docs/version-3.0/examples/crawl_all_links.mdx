---
id: crawl-all-links
title: Crawl all links on a website
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

import CheerioSource from '!!raw-loader!./crawl_all_links_cheerio.ts';
import PuppeteerSource from '!!raw-loader!./crawl_all_links_puppeteer.ts';
import PlaywrightSource from '!!raw-loader!./crawl_all_links_playwright.ts';

This example uses the `enqueueLinks()` method to add new links to the `RequestQueue` as the crawler navigates from page to page. If only the
required parameters are defined, all links will be crawled.

<Tabs groupId="crawler-type">

<TabItem value="cheerio_crawler" label="Cheerio Crawler" default>

Using `CheerioCrawler`:

<CodeBlock className="language-js">
	{CheerioSource}
</CodeBlock>

</TabItem>

<TabItem value="puppeteer_crawler" label="Puppeteer Crawler">

Using `PuppeteerCrawler`:

:::tip

To run this example on the Apify Platform, select the `apify/actor-node-puppeteer-chrome` image for your Dockerfile.

:::

<CodeBlock className="language-js">
	{PuppeteerSource}
</CodeBlock>

</TabItem>

<TabItem value="playwright_crawler" label="Playwright Crawler">

Using `PlaywrightCrawler`:

:::tip

To run this example on the Apify Platform, select the `apify/actor-node-playwright-chrome` image for your Dockerfile.

:::

<CodeBlock className="language-js">
	{PlaywrightSource}
</CodeBlock>

</TabItem>

</Tabs>
