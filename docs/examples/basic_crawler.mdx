---
id: basic-crawler
title: Basic crawler
---

import CodeBlock from '@theme/CodeBlock';
import ApiLink from '@site/src/components/ApiLink';
import { CrawleeApiLink } from '@site/src/components/CrawleeLinks';
import BasicCrawlerSource from '!!raw-loader!./basic_crawler.ts';

This is the most bare-bones example of the Apify SDK, which demonstrates some of its building blocks such as the <CrawleeApiLink to="basic-crawler/class/BasicCrawler">`BasicCrawler`</CrawleeApiLink>. You probably don't need to go this deep though, and it would be better to start with one of the full-featured crawlers
like <CrawleeApiLink to="cheerio-crawler/class/CheerioCrawler">`CheerioCrawler`</CrawleeApiLink> or <CrawleeApiLink to="playwright-crawler/class/PlaywrightCrawler">`PlaywrightCrawler`</CrawleeApiLink>.

The script simply downloads several web pages with plain HTTP requests using the [`got-scraping`](https://github.com/apify/got-scraping)
npm package and stores their raw HTML and URL in the default dataset. In local configuration, the data will be stored as JSON files in
`./storage/datasets/default`.

<CodeBlock className="language-js">
	{BasicCrawlerSource}
</CodeBlock>
